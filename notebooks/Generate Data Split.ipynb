{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac616ee",
   "metadata": {},
   "source": [
    "# Cholec Folder Split\n",
    "\n",
    "**NOTE: If you need to split your data, and you have both an `images` folder and `groundtruth` folder, proceed to `Generate Random Data Split` below**\n",
    "\n",
    "The following code was specially made for the `cholec` dataset\n",
    "\n",
    "- After downloading the Cholec Segmentation dataset from Kaggle, we organize the dataset into two main folders:\n",
    "    - `images` contains the input images for our semantic segmentation network\n",
    "    - `gt` contains the groundtruth image masks for our semantic segmentation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815588db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca09de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cholec_path = \"../../../Downloads/cholec/\"\n",
    "print(len(cholec_path))\n",
    "files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(cholec_path):\n",
    "    for filename in filenames:\n",
    "        curr_file = os.path.join(dirname, filename)\n",
    "        video_num = curr_file[33:35]\n",
    "        new_file_name = video_num + \"_\" + filename\n",
    "        if \"color\" in filename:\n",
    "            copy2(curr_file, \"../../../Downloads/cholec/gt/\")\n",
    "            original_name = \"../../../Downloads/cholec/gt/\" + filename\n",
    "            new_name = \"../../../Downloads/cholec/gt/\" + new_file_name\n",
    "            os.rename(original_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(cholec_path):\n",
    "    for filename in filenames:\n",
    "        curr_file = os.path.join(dirname, filename)\n",
    "        video_num = curr_file[33:35]\n",
    "        new_file_name = video_num + \"_\" + filename\n",
    "        if \"mask\" not in filename:\n",
    "            copy2(curr_file, \"../../../Downloads/cholec/images/\")\n",
    "            original_name = \"../../../Downloads/cholec/images/\" + filename\n",
    "            new_name = \"../../../Downloads/cholec/images/\" + new_file_name\n",
    "            os.rename(original_name, new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46110c7f",
   "metadata": {},
   "source": [
    "# Generate Random Data Split\n",
    "\n",
    "- The below code splits our data from `images` and `gt` into `train`/`val`/`test` sets with the following ratios:\n",
    "    - `train` = 0.7\n",
    "    - `val` = 0.15\n",
    "    - `test` = 0.15\n",
    "\n",
    "- This split code is adapted from the following Stanford CS230 Blog Post https://cs230.stanford.edu/blog/split/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207d3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = glob.glob(\"../../combined_synapse/images/*\")\n",
    "gt_list = glob.glob(\"../../combined_synapse/gt/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8c4b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list.sort()\n",
    "gt_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a718953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1e9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list = list(zip(image_list, gt_list))\n",
    "random.shuffle(combined_list)\n",
    "image_list, gt_list = zip(*combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba299e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_1 = int(0.15 * len(image_list))\n",
    "split_2 = int(0.3 * len(image_list))\n",
    "\n",
    "test_images, test_gt = image_list[:split_1], gt_list[:split_1]\n",
    "val_images, val_gt = image_list[split_1:split_2], gt_list[split_1:split_2]\n",
    "train_images, train_gt = image_list[split_2:], gt_list[split_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df11bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7005163511187608\n",
      "0.14974182444061962\n",
      "0.14974182444061962\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images) / len(image_list))\n",
    "print(len(test_images) / len(image_list))\n",
    "print(len(val_images) / len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f742f631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7005163511187608\n",
      "0.14974182444061962\n",
      "0.14974182444061962\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gt) / len(gt_list))\n",
    "print(len(test_gt) / len(gt_list))\n",
    "print(len(val_gt) / len(gt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b2936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_filenames = {'train_images': train_images,'val_images': val_images, 'test_images': test_images}\n",
    "gt_filenames = {'train_gt': train_gt,'val_gt': val_gt, 'test_gt': test_gt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3d9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_output_dir = \"../../combined_synapse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99c2ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save(filename, output_dir):\n",
    "    \"\"\"Resize the image contained in `filename` and save it to the `output_dir`\"\"\"\n",
    "    image = Image.open(filename)\n",
    "    save_path = os.path.join(output_dir, filename.split('/')[-1])\n",
    "    image.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff19a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/407 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../new_synapse/train_images\n",
      "Processing train_images data, saving preprocessed data to ../../new_synapse/train_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [03:38<00:00,  1.87it/s]\n",
      "  0%|          | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../new_synapse/val_images\n",
      "Processing val_images data, saving preprocessed data to ../../new_synapse/val_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:50<00:00,  1.74it/s]\n",
      "  0%|          | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../new_synapse/test_images\n",
      "Processing test_images data, saving preprocessed data to ../../new_synapse/test_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:48<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split in ['train_images', 'val_images', 'test_images']:\n",
    "    output_dir_split = os.path.join(im_output_dir, split)\n",
    "    print(output_dir_split)\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(output_dir_split):\n",
    "        os.mkdir(output_dir_split)\n",
    "    else:\n",
    "        print(\"Warning: dir {} already exists\".format(output_dir_split))\n",
    "    \n",
    "    print(\"Processing {} data, saving preprocessed data to {}\".format(split, output_dir_split))\n",
    "    for filename in tqdm(im_filenames[split]):\n",
    "        resize_and_save(filename, output_dir_split)\n",
    "\n",
    "\n",
    "print(\"Done building dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c061a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_output_dir = \"../../combined_synapse/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeebe673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/407 [00:00<00:46,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../combined_synapse/train_gt\n",
      "Processing train_gt data, saving preprocessed data to ../../combined_synapse/train_gt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [00:49<00:00,  8.30it/s]\n",
      "  1%|          | 1/87 [00:00<00:10,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../combined_synapse/val_gt\n",
      "Processing val_gt data, saving preprocessed data to ../../combined_synapse/val_gt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:09<00:00,  8.92it/s]\n",
      "  1%|          | 1/87 [00:00<00:09,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../combined_synapse/test_gt\n",
      "Processing test_gt data, saving preprocessed data to ../../combined_synapse/test_gt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:09<00:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split in ['train_gt', 'val_gt', 'test_gt']:\n",
    "    output_dir_split = os.path.join(gt_output_dir, split)\n",
    "    print(output_dir_split)\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(output_dir_split):\n",
    "        os.mkdir(output_dir_split)\n",
    "    else:\n",
    "        print(\"Warning: dir {} already exists\".format(output_dir_split))\n",
    "    \n",
    "    print(\"Processing {} data, saving preprocessed data to {}\".format(split, output_dir_split))\n",
    "    for filename in tqdm(gt_filenames[split]):\n",
    "        resize_and_save(filename, output_dir_split)\n",
    "\n",
    "\n",
    "print(\"Done building dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
